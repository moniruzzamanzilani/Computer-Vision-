{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path):\n",
    "    listOfFiles = os.listdir(path='cifar-10-batches-py/')\n",
    "    train = []\n",
    "    train_labels = []\n",
    "        \n",
    "        \n",
    "    print(\"Training files = \",listOfFiles[1:6])\n",
    "         #collecting Training data from path:\n",
    "    for file in listOfFiles[1:6]:\n",
    "        with open(path+file,'rb') as fo:\n",
    "            dict = pickle.load(fo,encoding='bytes')\n",
    "            train.append(dict[b'data'])\n",
    "            train_labels.append(dict[b'labels'])\n",
    "\n",
    "    print(len(train[4]))\n",
    "    dictData = {}\n",
    "    dictData['train_data'] = np.reshape(np.array(train),newshape=(np.array(train).shape[0]*np.array(train).shape[1],np.array(train).shape[2]))\n",
    "    print(np.array(train).shape[0])\n",
    "    dictData['train_labels'] = np.reshape(np.array(train_labels),newshape=(np.array(train_labels).shape[0]*np.array(train_labels).shape[1]))\n",
    "    return dictData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files =  ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']\n",
      "10000\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#load the dataset\n",
    "dataset = loadData(path='cifar-10-batches-py/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train_data'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train_labels'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualizing train sample and label\n",
    "temp = dataset['train_data'][15000]\n",
    "label = dataset['train_labels'][15000]\n",
    "# Since every row represents one example to re-map it to image we have to form three 32,32 matrix,\n",
    "#representing RGB values\n",
    "\n",
    "R = temp[0:1024].reshape(32,32)\n",
    "G = np.reshape(temp[1024:2048],newshape=(32,32))\n",
    "B = np.reshape(temp[2048:],newshape=(32,32))\n",
    "temp = np.dstack((R,G,B))   #for stacking all these 32,32 matrices.\n",
    "plt.imshow(temp)\n",
    "plt.xlabel(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train= dataset['train_data'],dataset['train_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the classifiers:\n",
    "#inputs will be in 2d and it will be of shape N X F where N = number of examples and F = number of features for each image.\n",
    "#labels will be of size N,1. This consists of labels for all N labels from 10 classes\n",
    "\n",
    "class kNearestNeighbour(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self,X,Y):\n",
    "        #Knn will remember all of its training data\n",
    "        self.Xtr = X\n",
    "        self.Ytr = Y\n",
    "        \n",
    "    def predict(self,X,k):\n",
    "        #to get no. of samples in train set \n",
    "        test_samples = X.shape[0]\n",
    "        Ypred = np.zeros(test_samples,dtype=self.Ytr.dtype)\n",
    "        \n",
    "        #Calculating the l1 distance between current samples of test and train set\n",
    "        for i in range(test_samples):\n",
    "            \n",
    "            print(\"Test example = \",i,end=\"\\r\")\n",
    "            #label_count is array of zeros used to store the count for each class while comparing neighbours\n",
    "            label_count = np.zeros(10,dtype=self.Ytr.dtype)    \n",
    "            dist = np.sum(np.abs(X[i,:] - self.Xtr),axis=1)   #take the absolute sum horizontally across columns\n",
    "            \n",
    "            \n",
    "            #idx will contain k smallest indices at the start of the list\n",
    "            #this is called partial sorting for more information look: https://docs.scipy.org/doc/numpy/reference/generated/numpy.argpartition.html\n",
    "            #min_ind will help us to slice through k indices which have minimum distance\n",
    "            idx = np.argpartition(dist,k)\n",
    "            min_ind = idx[:k]\n",
    "            \n",
    "            #This for loop iterates over min_ind and find the label present in train-set_Y for x\n",
    "            #and increase the count at that particular index whenever any label is repeated.\n",
    "            #Max value at any index is returned using np.argmax() and stored at ith index of Ypred i.e. predicted values\n",
    "            for x in min_ind:\n",
    "                label_count[int(self.Ytr[x])] +=1\n",
    "            Ypred[i] = np.argmax(label_count)\n",
    "\n",
    "        return Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n",
      "For k =  1\n",
      "Test example =  9999\n",
      "\n",
      "For k =  2\n",
      "Test example =  9999\n",
      "\n",
      "For k =  3\n",
      "Test example =  9999\n",
      "\n",
      "For k =  4\n",
      "Test example =  9999\n",
      "\n",
      "For k =  5\n",
      "Test example =  9999\n",
      "\n",
      "For k =  6\n",
      "Test example =  9999\n",
      "\n",
      "For k =  7\n",
      "Test example =  9999\n",
      "\n",
      "For k =  8\n",
      "Test example =  9999\n",
      "\n",
      "For k =  9\n",
      "Test example =  9999\n",
      "\n",
      "For k =  10\n",
      "Test example =  9999\n",
      "\n",
      "For k =  11\n",
      "Test example =  9999\n",
      "\n",
      "For k =  12\n",
      "Test example =  9999\n",
      "\n",
      "For k =  13\n",
      "Test example =  9999\n",
      "\n",
      "For k =  14\n",
      "Test example =  9999\n",
      "\n",
      "For k =  15\n",
      "Test example =  9999\n",
      "\n",
      "For k =  16\n",
      "Test example =  9999\n",
      "\n",
      "For k =  17\n",
      "Test example =  9999\n",
      "\n",
      "For k =  18\n",
      "Test example =  9999\n",
      "\n",
      "For k =  19\n",
      "Test example =  9999\n",
      "\n",
      "For k =  20\n",
      "Test example =  9999\n",
      "\n",
      "Fold : 1\n",
      "For k =  1\n",
      "Test example =  9999\n",
      "\n",
      "For k =  2\n",
      "Test example =  9999\n",
      "\n",
      "For k =  3\n",
      "Test example =  9999\n",
      "\n",
      "For k =  4\n",
      "Test example =  9999\n",
      "\n",
      "For k =  5\n",
      "Test example =  9999\n",
      "\n",
      "For k =  6\n",
      "Test example =  9999\n",
      "\n",
      "For k =  7\n",
      "Test example =  9999\n",
      "\n",
      "For k =  8\n",
      "Test example =  9999\n",
      "\n",
      "For k =  9\n",
      "Test example =  9999\n",
      "\n",
      "For k =  10\n",
      "Test example =  9999\n",
      "\n",
      "For k =  11\n",
      "Test example =  9999\n",
      "\n",
      "For k =  12\n",
      "Test example =  9999\n",
      "\n",
      "For k =  13\n",
      "Test example =  9999\n",
      "\n",
      "For k =  14\n",
      "Test example =  9999\n",
      "\n",
      "For k =  15\n",
      "Test example =  9999\n",
      "\n",
      "For k =  16\n",
      "Test example =  9999\n",
      "\n",
      "For k =  17\n",
      "Test example =  9999\n",
      "\n",
      "For k =  18\n",
      "Test example =  9999\n",
      "\n",
      "For k =  19\n",
      "Test example =  9999\n",
      "\n",
      "For k =  20\n",
      "Test example =  9999\n",
      "\n",
      "Fold : 2\n",
      "For k =  1\n",
      "Test example =  9999\n",
      "\n",
      "For k =  2\n",
      "Test example =  9999\n",
      "\n",
      "For k =  3\n",
      "Test example =  9999\n",
      "\n",
      "For k =  4\n",
      "Test example =  9999\n",
      "\n",
      "For k =  5\n",
      "Test example =  9999\n",
      "\n",
      "For k =  6\n",
      "Test example =  9999\n",
      "\n",
      "For k =  7\n",
      "Test example =  9999\n",
      "\n",
      "For k =  8\n",
      "Test example =  9999\n",
      "\n",
      "For k =  9\n",
      "Test example =  9999\n",
      "\n",
      "For k =  10\n",
      "Test example =  9999\n",
      "\n",
      "For k =  11\n",
      "Test example =  9999\n",
      "\n",
      "For k =  12\n",
      "Test example =  2465\r"
     ]
    }
   ],
   "source": [
    "#Splitting the data into 5 equal folds\n",
    "num_folds = 5\n",
    "num_training = 50000\n",
    "\n",
    "k_choices = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "\n",
    "# Check that training set can be equally divided into num_folds portions\n",
    "if num_training/num_folds % num_folds != 0.0:\n",
    "    raise ValueError('Number of training examples not evenly divisible by number of folds.')\n",
    "\n",
    "# Split training set into num_folds lists\n",
    "X_train_folds = np.split(X_train, num_folds)\n",
    "y_train_folds = np.split(y_train, num_folds)\n",
    "\n",
    "# A dictionary holding the accuracies for different values of k that we find\n",
    "# when running cross-validation. After running cross-validation,\n",
    "# k_to_accuracies[k] should be a list of length num_folds giving the different\n",
    "# accuracy values that we found when using that value of k.\n",
    "k_to_accuracies = {}\n",
    "\n",
    "# Perform k-fold cross validation to find the best value of k\n",
    "# Loop over num_folds in outer loop to reuse computed distances for all values of k\n",
    "for k in k_choices:\n",
    "    k_to_accuracies[k] = []\n",
    "    \n",
    "for idx in range(num_folds):\n",
    "    print(\"Fold :\", idx)\n",
    "    # Use bin with index idx as validation set, rest as training set \n",
    "    X_train_set = np.concatenate((*X_train_folds[:idx], *X_train_folds[idx+1:]), axis=0)\n",
    "    y_train_set = np.concatenate((*y_train_folds[:idx], *y_train_folds[idx+1:]), axis=0)\n",
    "    X_validation_set = X_train_folds[idx]\n",
    "    y_validation_set = y_train_folds[idx]   \n",
    "    num_validation_set = X_validation_set.shape[0]\n",
    "    # Train kNN classifier\n",
    "    knn = kNearestNeighbour()\n",
    "    knn.train(X_train_set, y_train_set)\n",
    "\n",
    "    \n",
    "    for k in k_choices:\n",
    "        print(\"For k = \",k,end=\"\\n\")\n",
    "        # Predict labels for validation set\n",
    "        y_validation_pred = knn.predict(X_validation_set,k)\n",
    "        # Check accuracy for validation set\n",
    "        accuracy = np.mean(y_validation_pred==y_validation_set)\n",
    "        k_to_accuracies[k].append(accuracy)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the computed accuracies\n",
    "for k in sorted(k_to_accuracies):\n",
    "    for accuracy in k_to_accuracies[k]:\n",
    "        print('k = %d, accuracy = %f' % (k, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the raw observations\n",
    "for k in k_choices:\n",
    "    accuracies = k_to_accuracies[k]\n",
    "    print('k = %d, average accuracy = %f' % (k, np.average(accuracies)))\n",
    "    plt.scatter([k] * len(accuracies), accuracies)\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
